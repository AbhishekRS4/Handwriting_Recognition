{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c38aaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c015612",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 32\n",
    "input_size = (64, 64)\n",
    "optimizer = 'adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ee89e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(physical_devices))\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfcca023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9e0dbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6df18a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 96)        34944     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 14, 14, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 96)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 6, 6, 96)          230496    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 6, 6, 96)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 96)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 2, 2, 16)          13840     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 2, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 2, 2, 16)          2320      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 2, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 2, 2, 22)          3190      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 2, 2, 22)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 22)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 22)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               6900      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 27)                5427      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 27)                0         \n",
      "=================================================================\n",
      "Total params: 357,317\n",
      "Trainable params: 357,317\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "image_shape = (64,64,3)\n",
    "np.random.seed(1000)\n",
    "model = Sequential()\n",
    "#First Convolutional layer\n",
    "model.add(Conv2D(filters=96, input_shape=image_shape, kernel_size=(11,11), strides=(4,4),padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
    "\n",
    "#Second Convolutional layer\n",
    "model.add(Conv2D(filters=96, kernel_size=(5,5), strides=(1,1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
    "\n",
    "#Third Convolutional layer\n",
    "model.add(Conv2D(filters=16, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#Fourth Convolutional layer\n",
    "model.add(Conv2D(filters=16, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#Fifth Convolutional layer\n",
    "model.add(Conv2D(filters=22, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same'))\n",
    "\n",
    "#Passing it to a fully connected layer, here we do the flatten!\n",
    "model.add(Flatten())\n",
    "\n",
    "#First Fully Connected layer has 4096 neurons\n",
    "model.add(Dense(300, input_shape=(64*64*3,)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#Add dropout to prevent overfitting\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#Second Fully Connected layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#Add Dropout\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#Output layer\n",
    "model.add(Dense(27))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=[\"accuracy\", recall_m, precision_m, f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "938af4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_data =\"char_recog/train\"\n",
    "path_test_data =\"char_recog/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5dfb7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 2500 files [00:11, 175.23 files/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-4511e4e80415>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msplitfolders\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msplitfolders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'char_training'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"char_recog\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1337\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\splitfolders\\split.py\u001b[0m in \u001b[0;36mratio\u001b[1;34m(input, output, seed, ratio, group_prefix, move)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mclass_dir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist_dirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         split_class_dir_ratio(\n\u001b[0m\u001b[0;32m     88\u001b[0m             \u001b[0mclass_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\splitfolders\\split.py\u001b[0m in \u001b[0;36msplit_class_dir_ratio\u001b[1;34m(class_dir, output, ratio, seed, prog_bar, group_prefix, move)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[0mli\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_train_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_val_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratio\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m     \u001b[0mcopy_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mli\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog_bar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\splitfolders\\split.py\u001b[0m in \u001b[0;36mcopy_files\u001b[1;34m(files_type, class_dir, output, prog_bar, move)\u001b[0m\n\u001b[0;32m    312\u001b[0m                     \u001b[0mcopy_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m                 \u001b[0mcopy_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopy2\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    433\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[0mdst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m     \u001b[0mcopyfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m     \u001b[0mcopystat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    281\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0m_WINDOWS\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfile_size\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m                 \u001b[0m_copyfileobj_readinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCOPY_BUFSIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m             \u001b[0mcopyfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import splitfolders\n",
    "\n",
    "splitfolders.ratio('char_training', output=\"char_recog\", seed=1337, ratio=(0.8, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dbb2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolder =[\"train\", \"val\"]\n",
    "for sf in subfolder:\n",
    "    mainfolder= f\"char_recog/{sf}\"\n",
    "    folders = os.listdir(mainfolder)\n",
    "    for folder in  folders:\n",
    "        files = os.listdir(f\"{mainfolder}/{folder}\")\n",
    "        for f in files:\n",
    "            impath = f\"{mainfolder}/{folder}/{f}\"\n",
    "            newfile = \"\".join(f.split(\".\")[0:-1])\n",
    "            newpath = f\"{mainfolder}/{folder}/{newfile}.png\"\n",
    "            img = Image.open(impath).convert(\"RGBA\")\n",
    "            img.save(newpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71271421",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_train_data = ImageDataGenerator(rescale=1./255, width_shift_range=0.1,\n",
    "        shear_range=0.15, zoom_range=0.1,\n",
    "        channel_shift_range=10., horizontal_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43547b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_test_data = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0b8e41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4425 images belonging to 27 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = gen_train_data.flow_from_directory(\n",
    "                path_train_data, \n",
    "                target_size=input_size, \n",
    "                batch_size=batch_size,\n",
    "                class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7082046e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1112 images belonging to 27 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = gen_train_data.flow_from_directory(\n",
    "                path_test_data,  # this is the target directory\n",
    "                target_size=input_size,  # all images will be resized to 64x64\n",
    "                batch_size=batch_size,\n",
    "                class_mode='categorical',subset='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "948a992c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "138/138 [==============================] - 14s 79ms/step - loss: 3.1651 - accuracy: 0.0633 - recall_m: 0.0011 - precision_m: 0.0166 - f1_m: 0.0019 - val_loss: 1.8182 - val_accuracy: 0.3695 - val_recall_m: 0.1287 - val_precision_m: 0.6680 - val_f1_m: 0.2132\n",
      "Epoch 2/100\n",
      "138/138 [==============================] - 10s 73ms/step - loss: 1.6982 - accuracy: 0.4270 - recall_m: 0.2362 - precision_m: 0.6018 - f1_m: 0.3252 - val_loss: 0.6840 - val_accuracy: 0.8061 - val_recall_m: 0.7307 - val_precision_m: 0.9107 - val_f1_m: 0.8096\n",
      "Epoch 3/100\n",
      "138/138 [==============================] - 10s 72ms/step - loss: 0.8792 - accuracy: 0.7331 - recall_m: 0.6441 - precision_m: 0.8498 - f1_m: 0.7298 - val_loss: 0.5683 - val_accuracy: 0.8263 - val_recall_m: 0.7454 - val_precision_m: 0.9297 - val_f1_m: 0.8260\n",
      "Epoch 4/100\n",
      "138/138 [==============================] - 10s 74ms/step - loss: 0.5880 - accuracy: 0.8296 - recall_m: 0.7616 - precision_m: 0.9006 - f1_m: 0.8236 - val_loss: 0.3845 - val_accuracy: 0.8824 - val_recall_m: 0.8382 - val_precision_m: 0.9228 - val_f1_m: 0.8775\n",
      "Epoch 5/100\n",
      "138/138 [==============================] - 10s 74ms/step - loss: 0.4866 - accuracy: 0.8472 - recall_m: 0.8056 - precision_m: 0.8972 - f1_m: 0.8480 - val_loss: 0.3843 - val_accuracy: 0.8824 - val_recall_m: 0.8428 - val_precision_m: 0.9329 - val_f1_m: 0.8850\n",
      "Epoch 6/100\n",
      "138/138 [==============================] - 11s 83ms/step - loss: 0.4719 - accuracy: 0.8585 - recall_m: 0.8118 - precision_m: 0.9039 - f1_m: 0.8544 - val_loss: 0.3613 - val_accuracy: 0.9007 - val_recall_m: 0.8713 - val_precision_m: 0.9297 - val_f1_m: 0.8989\n",
      "Epoch 7/100\n",
      "138/138 [==============================] - 10s 74ms/step - loss: 0.4275 - accuracy: 0.8669 - recall_m: 0.8253 - precision_m: 0.9103 - f1_m: 0.8650 - val_loss: 0.3324 - val_accuracy: 0.8980 - val_recall_m: 0.8704 - val_precision_m: 0.9231 - val_f1_m: 0.8955\n",
      "Epoch 8/100\n",
      "138/138 [==============================] - 11s 79ms/step - loss: 0.3476 - accuracy: 0.8939 - recall_m: 0.8676 - precision_m: 0.9305 - f1_m: 0.8975 - val_loss: 0.2779 - val_accuracy: 0.9081 - val_recall_m: 0.8943 - val_precision_m: 0.9294 - val_f1_m: 0.91136 - \n",
      "Epoch 9/100\n",
      "138/138 [==============================] - 10s 75ms/step - loss: 0.3791 - accuracy: 0.8914 - recall_m: 0.8577 - precision_m: 0.9282 - f1_m: 0.8909 - val_loss: 0.2968 - val_accuracy: 0.9099 - val_recall_m: 0.8952 - val_precision_m: 0.9346 - val_f1_m: 0.9139\n",
      "Epoch 10/100\n",
      "138/138 [==============================] - 10s 74ms/step - loss: 0.3030 - accuracy: 0.9075 - recall_m: 0.8877 - precision_m: 0.9407 - f1_m: 0.9128 - val_loss: 0.3491 - val_accuracy: 0.8879 - val_recall_m: 0.8759 - val_precision_m: 0.9200 - val_f1_m: 0.8971\n",
      "Epoch 11/100\n",
      "138/138 [==============================] - 10s 75ms/step - loss: 0.2841 - accuracy: 0.9101 - recall_m: 0.8929 - precision_m: 0.9332 - f1_m: 0.9123 - val_loss: 0.2940 - val_accuracy: 0.9136 - val_recall_m: 0.9035 - val_precision_m: 0.9326 - val_f1_m: 0.9176\n",
      "Epoch 12/100\n",
      "138/138 [==============================] - 10s 75ms/step - loss: 0.2861 - accuracy: 0.9135 - recall_m: 0.8944 - precision_m: 0.9406 - f1_m: 0.9165 - val_loss: 0.2780 - val_accuracy: 0.9182 - val_recall_m: 0.8989 - val_precision_m: 0.9380 - val_f1_m: 0.9178\n",
      "Epoch 13/100\n",
      "138/138 [==============================] - 10s 75ms/step - loss: 0.2397 - accuracy: 0.9270 - recall_m: 0.9075 - precision_m: 0.9483 - f1_m: 0.9271 - val_loss: 0.2874 - val_accuracy: 0.9127 - val_recall_m: 0.9017 - val_precision_m: 0.9325 - val_f1_m: 0.91668 - precision_m: 0.948\n",
      "Epoch 14/100\n",
      "138/138 [==============================] - 10s 74ms/step - loss: 0.2512 - accuracy: 0.9181 - recall_m: 0.9045 - precision_m: 0.9454 - f1_m: 0.9241 - val_loss: 0.3473 - val_accuracy: 0.8925 - val_recall_m: 0.8695 - val_precision_m: 0.9185 - val_f1_m: 0.8929\n",
      "Epoch 15/100\n",
      "138/138 [==============================] - 10s 74ms/step - loss: 0.2482 - accuracy: 0.9237 - recall_m: 0.9054 - precision_m: 0.9521 - f1_m: 0.9279 - val_loss: 0.3194 - val_accuracy: 0.9118 - val_recall_m: 0.8989 - val_precision_m: 0.9272 - val_f1_m: 0.9126\n",
      "Epoch 16/100\n",
      "138/138 [==============================] - 10s 75ms/step - loss: 0.2359 - accuracy: 0.9238 - recall_m: 0.9074 - precision_m: 0.9440 - f1_m: 0.9251 - val_loss: 0.3198 - val_accuracy: 0.9182 - val_recall_m: 0.9081 - val_precision_m: 0.9323 - val_f1_m: 0.9198\n",
      "Epoch 17/100\n",
      "138/138 [==============================] - 10s 74ms/step - loss: 0.2356 - accuracy: 0.9269 - recall_m: 0.9106 - precision_m: 0.9449 - f1_m: 0.9272 - val_loss: 0.2569 - val_accuracy: 0.9210 - val_recall_m: 0.9136 - val_precision_m: 0.9378 - val_f1_m: 0.9254\n",
      "Epoch 18/100\n",
      "138/138 [==============================] - 10s 76ms/step - loss: 0.2199 - accuracy: 0.9407 - recall_m: 0.9257 - precision_m: 0.9584 - f1_m: 0.9415 - val_loss: 0.2953 - val_accuracy: 0.9154 - val_recall_m: 0.9044 - val_precision_m: 0.9327 - val_f1_m: 0.9181\n",
      "Epoch 19/100\n",
      "138/138 [==============================] - 11s 78ms/step - loss: 0.2273 - accuracy: 0.9291 - recall_m: 0.9146 - precision_m: 0.9507 - f1_m: 0.9321 - val_loss: 0.3242 - val_accuracy: 0.9108 - val_recall_m: 0.8989 - val_precision_m: 0.9305 - val_f1_m: 0.9142\n",
      "Epoch 20/100\n",
      "138/138 [==============================] - 10s 74ms/step - loss: 0.2031 - accuracy: 0.9360 - recall_m: 0.9194 - precision_m: 0.9514 - f1_m: 0.9348 - val_loss: 0.3160 - val_accuracy: 0.9118 - val_recall_m: 0.9007 - val_precision_m: 0.9308 - val_f1_m: 0.9153\n",
      "Epoch 21/100\n",
      "138/138 [==============================] - 10s 74ms/step - loss: 0.2085 - accuracy: 0.9352 - recall_m: 0.9190 - precision_m: 0.9525 - f1_m: 0.9351 - val_loss: 0.3239 - val_accuracy: 0.9228 - val_recall_m: 0.9145 - val_precision_m: 0.9405 - val_f1_m: 0.9272\n",
      "Epoch 22/100\n",
      "138/138 [==============================] - 10s 75ms/step - loss: 0.1794 - accuracy: 0.9454 - recall_m: 0.9338 - precision_m: 0.9610 - f1_m: 0.9469 - val_loss: 0.2878 - val_accuracy: 0.9237 - val_recall_m: 0.9099 - val_precision_m: 0.9405 - val_f1_m: 0.9247\n",
      "Epoch 23/100\n",
      "138/138 [==============================] - 10s 74ms/step - loss: 0.2017 - accuracy: 0.9403 - recall_m: 0.9236 - precision_m: 0.9560 - f1_m: 0.9393 - val_loss: 0.2691 - val_accuracy: 0.9191 - val_recall_m: 0.9099 - val_precision_m: 0.9320 - val_f1_m: 0.9206cy: 0.9392 - - ETA: 1s - loss: 0.2024 - accuracy: 0.9398 - recall_m:\n",
      "Epoch 24/100\n",
      "138/138 [==============================] - 10s 76ms/step - loss: 0.1926 - accuracy: 0.9418 - recall_m: 0.9275 - precision_m: 0.9553 - f1_m: 0.9409 - val_loss: 0.2968 - val_accuracy: 0.9292 - val_recall_m: 0.9246 - val_precision_m: 0.9412 - val_f1_m: 0.9328\n",
      "Epoch 25/100\n",
      "138/138 [==============================] - 11s 77ms/step - loss: 0.2012 - accuracy: 0.9386 - recall_m: 0.9306 - precision_m: 0.9517 - f1_m: 0.9408 - val_loss: 0.2880 - val_accuracy: 0.9274 - val_recall_m: 0.9228 - val_precision_m: 0.9365 - val_f1_m: 0.9295\n",
      "Epoch 26/100\n",
      "138/138 [==============================] - 10s 74ms/step - loss: 0.1701 - accuracy: 0.9432 - recall_m: 0.9354 - precision_m: 0.9533 - f1_m: 0.9441 - val_loss: 0.3312 - val_accuracy: 0.9219 - val_recall_m: 0.9099 - val_precision_m: 0.9366 - val_f1_m: 0.9229\n",
      "Epoch 27/100\n",
      "138/138 [==============================] - 12s 86ms/step - loss: 0.1963 - accuracy: 0.9429 - recall_m: 0.9276 - precision_m: 0.9570 - f1_m: 0.9418 - val_loss: 0.2355 - val_accuracy: 0.9265 - val_recall_m: 0.9154 - val_precision_m: 0.9431 - val_f1_m: 0.9289accuracy: 0.9428 - recall_\n",
      "Epoch 28/100\n",
      "138/138 [==============================] - 11s 82ms/step - loss: 0.1879 - accuracy: 0.9453 - recall_m: 0.9352 - precision_m: 0.9617 - f1_m: 0.9481 - val_loss: 0.2719 - val_accuracy: 0.9228 - val_recall_m: 0.9182 - val_precision_m: 0.9405 - val_f1_m: 0.9291 - ETA: 1s - loss: 0.1894 - accuracy: 0.9450 - recall_m:\n",
      "Epoch 29/100\n",
      "138/138 [==============================] - 11s 78ms/step - loss: 0.1908 - accuracy: 0.9438 - recall_m: 0.9360 - precision_m: 0.9553 - f1_m: 0.9454 - val_loss: 0.2646 - val_accuracy: 0.9301 - val_recall_m: 0.9246 - val_precision_m: 0.9462 - val_f1_m: 0.9352- accuracy: 0.9492 - recall_m: 0.9423 - precision_m: 0.9 - ETA: 6s - loss: 0.1713 - accuracy: 0.9490 - recall_m: 0.9427  - ETA: 5s - loss: 0.1804 - accuracy: 0.94\n",
      "Epoch 30/100\n",
      "138/138 [==============================] - 11s 77ms/step - loss: 0.1606 - accuracy: 0.9514 - recall_m: 0.9432 - precision_m: 0.9640 - f1_m: 0.9533 - val_loss: 0.2755 - val_accuracy: 0.9338 - val_recall_m: 0.9283 - val_precision_m: 0.9465 - val_f1_m: 0.9372accuracy: 0.9516 - recall_m: 0.9435 - prec\n",
      "Epoch 31/100\n",
      "138/138 [==============================] - 11s 79ms/step - loss: 0.1141 - accuracy: 0.9628 - recall_m: 0.9560 - precision_m: 0.9731 - f1_m: 0.9643 - val_loss: 0.3324 - val_accuracy: 0.9219 - val_recall_m: 0.9182 - val_precision_m: 0.9307 - val_f1_m: 0.9243.0903 - accuracy: 0.9716 - recall_m: - ETA: 6s - loss: 0.1044 - accuracy: 0.9677 - recall_m: 0.9623 - prec - ETA - ETA: \n",
      "Epoch 32/100\n",
      "138/138 [==============================] - 10s 73ms/step - loss: 0.1663 - accuracy: 0.9477 - recall_m: 0.9365 - precision_m: 0.9603 - f1_m: 0.9480 - val_loss: 0.2805 - val_accuracy: 0.9329 - val_recall_m: 0.9292 - val_precision_m: 0.9459 - val_f1_m: 0.9374\n",
      "Epoch 33/100\n",
      "138/138 [==============================] - 10s 74ms/step - loss: 0.1459 - accuracy: 0.9518 - recall_m: 0.9449 - precision_m: 0.9625 - f1_m: 0.9534 - val_loss: 0.2458 - val_accuracy: 0.9403 - val_recall_m: 0.9320 - val_precision_m: 0.9531 - val_f1_m: 0.9423\n",
      "Epoch 34/100\n",
      "138/138 [==============================] - 10s 73ms/step - loss: 0.1036 - accuracy: 0.9645 - recall_m: 0.9598 - precision_m: 0.9708 - f1_m: 0.9651 - val_loss: 0.2939 - val_accuracy: 0.9283 - val_recall_m: 0.9145 - val_precision_m: 0.9451 - val_f1_m: 0.9294\n",
      "Epoch 35/100\n",
      "138/138 [==============================] - 10s 73ms/step - loss: 0.1249 - accuracy: 0.9617 - recall_m: 0.9517 - precision_m: 0.9666 - f1_m: 0.9590 - val_loss: 0.2972 - val_accuracy: 0.9338 - val_recall_m: 0.9256 - val_precision_m: 0.9410 - val_f1_m: 0.9331\n",
      "Epoch 36/100\n",
      "138/138 [==============================] - 10s 73ms/step - loss: 0.1362 - accuracy: 0.9559 - recall_m: 0.9485 - precision_m: 0.9669 - f1_m: 0.9575 - val_loss: 0.2940 - val_accuracy: 0.9320 - val_recall_m: 0.9256 - val_precision_m: 0.9384 - val_f1_m: 0.9318\n",
      "Epoch 37/100\n",
      "138/138 [==============================] - 10s 72ms/step - loss: 0.1416 - accuracy: 0.9569 - recall_m: 0.9495 - precision_m: 0.9672 - f1_m: 0.9582 - val_loss: 0.3186 - val_accuracy: 0.9210 - val_recall_m: 0.9154 - val_precision_m: 0.9343 - val_f1_m: 0.9246\n",
      "Epoch 38/100\n",
      "138/138 [==============================] - 10s 76ms/step - loss: 0.1567 - accuracy: 0.9527 - recall_m: 0.9404 - precision_m: 0.9611 - f1_m: 0.9504 - val_loss: 0.3384 - val_accuracy: 0.9256 - val_recall_m: 0.9237 - val_precision_m: 0.9338 - val_f1_m: 0.9287\n",
      "Epoch 39/100\n",
      "138/138 [==============================] - 10s 73ms/step - loss: 0.0967 - accuracy: 0.9696 - recall_m: 0.9610 - precision_m: 0.9742 - f1_m: 0.9674 - val_loss: 0.2610 - val_accuracy: 0.9311 - val_recall_m: 0.9265 - val_precision_m: 0.9464 - val_f1_m: 0.9362\n",
      "Epoch 40/100\n",
      "138/138 [==============================] - 10s 73ms/step - loss: 0.1242 - accuracy: 0.9640 - recall_m: 0.9548 - precision_m: 0.9736 - f1_m: 0.9640 - val_loss: 0.3988 - val_accuracy: 0.9237 - val_recall_m: 0.9210 - val_precision_m: 0.9297 - val_f1_m: 0.9252\n",
      "Epoch 41/100\n",
      "138/138 [==============================] - 12s 86ms/step - loss: 0.1390 - accuracy: 0.9534 - recall_m: 0.9473 - precision_m: 0.9606 - f1_m: 0.9538 - val_loss: 0.2829 - val_accuracy: 0.9228 - val_recall_m: 0.9154 - val_precision_m: 0.9336 - val_f1_m: 0.9243\n",
      "Epoch 42/100\n",
      "138/138 [==============================] - 11s 81ms/step - loss: 0.1163 - accuracy: 0.9641 - recall_m: 0.9557 - precision_m: 0.9729 - f1_m: 0.9640 - val_loss: 0.3246 - val_accuracy: 0.9311 - val_recall_m: 0.9256 - val_precision_m: 0.9418 - val_f1_m: 0.9335\n",
      "Epoch 43/100\n",
      "138/138 [==============================] - 10s 73ms/step - loss: 0.1228 - accuracy: 0.9596 - recall_m: 0.9538 - precision_m: 0.9669 - f1_m: 0.9602 - val_loss: 0.3278 - val_accuracy: 0.9347 - val_recall_m: 0.9283 - val_precision_m: 0.9457 - val_f1_m: 0.9368\n",
      "Epoch 44/100\n",
      "138/138 [==============================] - 10s 76ms/step - loss: 0.1193 - accuracy: 0.9629 - recall_m: 0.9556 - precision_m: 0.9704 - f1_m: 0.9628 - val_loss: 0.3037 - val_accuracy: 0.9283 - val_recall_m: 0.9237 - val_precision_m: 0.9392 - val_f1_m: 0.9313\n",
      "Epoch 45/100\n",
      "138/138 [==============================] - 11s 78ms/step - loss: 0.1292 - accuracy: 0.9630 - recall_m: 0.9539 - precision_m: 0.9682 - f1_m: 0.9609 - val_loss: 0.3456 - val_accuracy: 0.9228 - val_recall_m: 0.9173 - val_precision_m: 0.9319 - val_f1_m: 0.9244ecision_m: 0.9730 - f1 - ETA: 6s - loss: 0.1199 - accuracy: 0.9687 - recall_ - ETA: 1s - loss: 0.1296 - accuracy: \n",
      "Epoch 46/100\n",
      "138/138 [==============================] - 10s 75ms/step - loss: 0.1352 - accuracy: 0.9606 - recall_m: 0.9536 - precision_m: 0.9724 - f1_m: 0.9628 - val_loss: 0.3252 - val_accuracy: 0.9347 - val_recall_m: 0.9283 - val_precision_m: 0.9393 - val_f1_m: 0.9337\n",
      "Epoch 47/100\n",
      "138/138 [==============================] - 10s 76ms/step - loss: 0.0863 - accuracy: 0.9711 - recall_m: 0.9688 - precision_m: 0.9758 - f1_m: 0.9722 - val_loss: 0.2696 - val_accuracy: 0.9467 - val_recall_m: 0.9393 - val_precision_m: 0.9535 - val_f1_m: 0.9463\n",
      "Epoch 48/100\n",
      "138/138 [==============================] - 10s 76ms/step - loss: 0.1014 - accuracy: 0.9664 - recall_m: 0.9613 - precision_m: 0.9724 - f1_m: 0.9668 - val_loss: 0.3058 - val_accuracy: 0.9375 - val_recall_m: 0.9347 - val_precision_m: 0.9451 - val_f1_m: 0.9398\n",
      "Epoch 49/100\n",
      "138/138 [==============================] - 10s 74ms/step - loss: 0.0996 - accuracy: 0.9659 - recall_m: 0.9612 - precision_m: 0.9746 - f1_m: 0.9678 - val_loss: 0.3837 - val_accuracy: 0.9200 - val_recall_m: 0.9145 - val_precision_m: 0.9298 - val_f1_m: 0.9220\n",
      "Epoch 50/100\n",
      "138/138 [==============================] - 11s 78ms/step - loss: 0.1126 - accuracy: 0.9712 - recall_m: 0.9606 - precision_m: 0.9754 - f1_m: 0.9679 - val_loss: 0.3484 - val_accuracy: 0.9311 - val_recall_m: 0.9283 - val_precision_m: 0.9368 - val_f1_m: 0.9325\n",
      "Epoch 51/100\n",
      "138/138 [==============================] - 11s 78ms/step - loss: 0.1689 - accuracy: 0.9580 - recall_m: 0.9468 - precision_m: 0.9659 - f1_m: 0.9561 - val_loss: 0.2784 - val_accuracy: 0.9375 - val_recall_m: 0.9347 - val_precision_m: 0.9477 - val_f1_m: 0.9411cy: 0.9577 - recall_m: 0.9464 - precision_m: 0.9651 - f1_m: 0.95 - ETA: 2s - loss: 0.1738 - accura - ETA: 0s - loss: 0.1695 - accuracy: 0.9579 - recall_m: 0.9466 - precision_m: 0.9658 - f1_m\n",
      "Epoch 52/100\n",
      "138/138 [==============================] - 10s 75ms/step - loss: 0.1180 - accuracy: 0.9636 - recall_m: 0.9569 - precision_m: 0.9715 - f1_m: 0.9640 - val_loss: 0.4325 - val_accuracy: 0.9200 - val_recall_m: 0.9154 - val_precision_m: 0.9284 - val_f1_m: 0.9218186 - accu\n",
      "Epoch 53/100\n",
      "138/138 [==============================] - 10s 76ms/step - loss: 0.1340 - accuracy: 0.9630 - recall_m: 0.9547 - precision_m: 0.9682 - f1_m: 0.9613 - val_loss: 0.3394 - val_accuracy: 0.9173 - val_recall_m: 0.9118 - val_precision_m: 0.9361 - val_f1_m: 0.9236\n",
      "Epoch 54/100\n",
      "138/138 [==============================] - 10s 77ms/step - loss: 0.1285 - accuracy: 0.9692 - recall_m: 0.9619 - precision_m: 0.9740 - f1_m: 0.9678 - val_loss: 0.3009 - val_accuracy: 0.9393 - val_recall_m: 0.9357 - val_precision_m: 0.9470 - val_f1_m: 0.9412\n",
      "Epoch 55/100\n",
      "138/138 [==============================] - 12s 85ms/step - loss: 0.0817 - accuracy: 0.9724 - recall_m: 0.9674 - precision_m: 0.9773 - f1_m: 0.9723 - val_loss: 0.3189 - val_accuracy: 0.9311 - val_recall_m: 0.9274 - val_precision_m: 0.9413 - val_f1_m: 0.9342\n",
      "Epoch 56/100\n",
      "138/138 [==============================] - 11s 81ms/step - loss: 0.0967 - accuracy: 0.9714 - recall_m: 0.9689 - precision_m: 0.9753 - f1_m: 0.9720 - val_loss: 0.4079 - val_accuracy: 0.9301 - val_recall_m: 0.9210 - val_precision_m: 0.9390 - val_f1_m: 0.9297\n",
      "Epoch 57/100\n",
      "138/138 [==============================] - 12s 84ms/step - loss: 0.1177 - accuracy: 0.9623 - recall_m: 0.9580 - precision_m: 0.9707 - f1_m: 0.9642 - val_loss: 0.3490 - val_accuracy: 0.9127 - val_recall_m: 0.9090 - val_precision_m: 0.9299 - val_f1_m: 0.9191_m: 0.9537 - precision_m: 0.9680 - f1 - E\n",
      "Epoch 58/100\n",
      "138/138 [==============================] - 10s 73ms/step - loss: 0.1392 - accuracy: 0.9605 - recall_m: 0.9520 - precision_m: 0.9700 - f1_m: 0.9607 - val_loss: 0.3048 - val_accuracy: 0.9449 - val_recall_m: 0.9347 - val_precision_m: 0.9537 - val_f1_m: 0.9439\n",
      "Epoch 59/100\n",
      "138/138 [==============================] - 10s 76ms/step - loss: 0.0786 - accuracy: 0.9771 - recall_m: 0.9700 - precision_m: 0.9821 - f1_m: 0.9759 - val_loss: 0.3558 - val_accuracy: 0.9338 - val_recall_m: 0.9292 - val_precision_m: 0.9424 - val_f1_m: 0.9357l_m: 0.9695 - precision_m: 0.9821  - ETA: 1s - loss: 0.0790 - accuracy: 0.9771 - recall_m: 0\n",
      "Epoch 60/100\n",
      "138/138 [==============================] - 11s 77ms/step - loss: 0.0975 - accuracy: 0.9737 - recall_m: 0.9671 - precision_m: 0.9764 - f1_m: 0.9717 - val_loss: 0.3412 - val_accuracy: 0.9403 - val_recall_m: 0.9320 - val_precision_m: 0.9479 - val_f1_m: 0.9398\n",
      "Epoch 61/100\n",
      "138/138 [==============================] - 10s 74ms/step - loss: 0.0879 - accuracy: 0.9692 - recall_m: 0.9659 - precision_m: 0.9754 - f1_m: 0.9706 - val_loss: 0.3200 - val_accuracy: 0.9403 - val_recall_m: 0.9357 - val_precision_m: 0.9498 - val_f1_m: 0.9426\n",
      "Epoch 62/100\n",
      "138/138 [==============================] - 10s 73ms/step - loss: 0.0884 - accuracy: 0.9723 - recall_m: 0.9667 - precision_m: 0.9781 - f1_m: 0.9723 - val_loss: 0.3523 - val_accuracy: 0.9311 - val_recall_m: 0.9301 - val_precision_m: 0.9395 - val_f1_m: 0.9347\n",
      "Epoch 63/100\n",
      "138/138 [==============================] - 11s 78ms/step - loss: 0.1328 - accuracy: 0.9683 - recall_m: 0.9616 - precision_m: 0.9728 - f1_m: 0.9671 - val_loss: 0.4182 - val_accuracy: 0.9256 - val_recall_m: 0.9191 - val_precision_m: 0.9337 - val_f1_m: 0.9262\n",
      "Epoch 64/100\n",
      "138/138 [==============================] - 12s 86ms/step - loss: 0.1027 - accuracy: 0.9721 - recall_m: 0.9671 - precision_m: 0.9789 - f1_m: 0.9728 - val_loss: 0.4141 - val_accuracy: 0.9329 - val_recall_m: 0.9311 - val_precision_m: 0.9476 - val_f1_m: 0.9391\n",
      "Epoch 65/100\n",
      "138/138 [==============================] - 11s 77ms/step - loss: 0.0985 - accuracy: 0.9713 - recall_m: 0.9671 - precision_m: 0.9745 - f1_m: 0.9707 - val_loss: 0.4039 - val_accuracy: 0.9256 - val_recall_m: 0.9246 - val_precision_m: 0.9289 - val_f1_m: 0.9267\n",
      "Epoch 66/100\n",
      "138/138 [==============================] - 10s 75ms/step - loss: 0.0706 - accuracy: 0.9772 - recall_m: 0.9744 - precision_m: 0.9793 - f1_m: 0.9768 - val_loss: 0.3180 - val_accuracy: 0.9357 - val_recall_m: 0.9311 - val_precision_m: 0.9440 - val_f1_m: 0.9374\n",
      "Epoch 67/100\n",
      "138/138 [==============================] - 10s 73ms/step - loss: 0.0784 - accuracy: 0.9804 - recall_m: 0.9758 - precision_m: 0.9836 - f1_m: 0.9796 - val_loss: 0.3820 - val_accuracy: 0.9338 - val_recall_m: 0.9311 - val_precision_m: 0.9405 - val_f1_m: 0.9357\n",
      "Epoch 68/100\n",
      "138/138 [==============================] - 10s 75ms/step - loss: 0.0736 - accuracy: 0.9797 - recall_m: 0.9772 - precision_m: 0.9834 - f1_m: 0.9802 - val_loss: 0.3369 - val_accuracy: 0.9292 - val_recall_m: 0.9219 - val_precision_m: 0.9417 - val_f1_m: 0.9315\n",
      "Epoch 69/100\n",
      "138/138 [==============================] - 11s 77ms/step - loss: 0.0671 - accuracy: 0.9825 - recall_m: 0.9794 - precision_m: 0.9848 - f1_m: 0.9821 - val_loss: 0.3889 - val_accuracy: 0.9292 - val_recall_m: 0.9274 - val_precision_m: 0.9371 - val_f1_m: 0.9322\n",
      "Epoch 70/100\n",
      "138/138 [==============================] - 10s 74ms/step - loss: 0.1476 - accuracy: 0.9659 - recall_m: 0.9603 - precision_m: 0.9741 - f1_m: 0.9670 - val_loss: 0.3269 - val_accuracy: 0.9393 - val_recall_m: 0.9375 - val_precision_m: 0.9507 - val_f1_m: 0.94392 - accuracy: 0.9660 - recall_m: 0.9604 - precision_m: 0.9742 - f1_m\n",
      "Epoch 71/100\n",
      "138/138 [==============================] - 10s 75ms/step - loss: 0.0562 - accuracy: 0.9840 - recall_m: 0.9795 - precision_m: 0.9858 - f1_m: 0.9826 - val_loss: 0.3778 - val_accuracy: 0.9375 - val_recall_m: 0.9347 - val_precision_m: 0.9425 - val_f1_m: 0.9386\n",
      "Epoch 72/100\n",
      "138/138 [==============================] - 10s 73ms/step - loss: 0.0914 - accuracy: 0.9738 - recall_m: 0.9686 - precision_m: 0.9796 - f1_m: 0.9740 - val_loss: 0.4569 - val_accuracy: 0.9154 - val_recall_m: 0.9136 - val_precision_m: 0.9246 - val_f1_m: 0.91900.9745 - recall_m: 0.9678 - precision_m: 0.9806 - f1_m: 0. - ETA: 4s - loss: 0.0911 - accuracy: 0.9745 - recall_m: 0.9679 - precision_m: 0.9805 - f1_m - ETA - ETA: 1s - loss: 0.0886 - accuracy: 0.\n",
      "Epoch 73/100\n",
      "138/138 [==============================] - 10s 75ms/step - loss: 0.1105 - accuracy: 0.9714 - recall_m: 0.9642 - precision_m: 0.9773 - f1_m: 0.9706 - val_loss: 0.4215 - val_accuracy: 0.9347 - val_recall_m: 0.9320 - val_precision_m: 0.9398 - val_f1_m: 0.9358accuracy: 0.9714 - recall_m: 0.9641 - precision_m: 0.9773 - f1_m: 0.97\n",
      "Epoch 74/100\n",
      "138/138 [==============================] - 11s 77ms/step - loss: 0.0726 - accuracy: 0.9791 - recall_m: 0.9745 - precision_m: 0.9826 - f1_m: 0.9785 - val_loss: 0.3745 - val_accuracy: 0.9375 - val_recall_m: 0.9347 - val_precision_m: 0.9434 - val_f1_m: 0.93900.9795 - recall_m:\n",
      "Epoch 75/100\n",
      "138/138 [==============================] - 11s 77ms/step - loss: 0.0993 - accuracy: 0.9746 - recall_m: 0.9704 - precision_m: 0.9775 - f1_m: 0.9738 - val_loss: 0.2944 - val_accuracy: 0.9458 - val_recall_m: 0.9393 - val_precision_m: 0.9508 - val_f1_m: 0.9450ecal - ETA: 5s - loss: 0.0984 - accuracy: 0.9773 - recall_m: 0.9739 - precision_m: 0.9792 - f1_m: 0. - ETA: 5s - loss: 0.0986 - accuracy: 0.9771 - recall_m: 0.9738 - precision_m: 0.9791 - f1_m - ETA: 4s - - ETA: 2s - loss: 0.1009 - \n",
      "Epoch 76/100\n",
      "138/138 [==============================] - 12s 89ms/step - loss: 0.0665 - accuracy: 0.9792 - recall_m: 0.9737 - precision_m: 0.9817 - f1_m: 0.9776 - val_loss: 0.3757 - val_accuracy: 0.9393 - val_recall_m: 0.9384 - val_precision_m: 0.9436 - val_f1_m: 0.9410\n",
      "Epoch 77/100\n",
      "138/138 [==============================] - 12s 90ms/step - loss: 0.0608 - accuracy: 0.9831 - recall_m: 0.9801 - precision_m: 0.9856 - f1_m: 0.9828 - val_loss: 0.3792 - val_accuracy: 0.9301 - val_recall_m: 0.9283 - val_precision_m: 0.9409 - val_f1_m: 0.9344curacy: 0.9868 - recall_m: 0.9835 - precision_m: 0.9891 - f1_m: 0.98 - ETA: 6s - loss: 0.0601 - accuracy: 0.9867 - recall_m: - ETA: 1s - loss: 0.0592 - accuracy: 0.9837 - recall_m: 0.9807 - \n",
      "Epoch 78/100\n",
      "138/138 [==============================] - 11s 83ms/step - loss: 0.0539 - accuracy: 0.9837 - recall_m: 0.9813 - precision_m: 0.9878 - f1_m: 0.9845 - val_loss: 0.3568 - val_accuracy: 0.9393 - val_recall_m: 0.9347 - val_precision_m: 0.9460 - val_f1_m: 0.9403ion_m: 0 - ETA: 2s - loss: 0.0531 - ac\n",
      "Epoch 79/100\n",
      "138/138 [==============================] - 10s 76ms/step - loss: 0.0815 - accuracy: 0.9777 - recall_m: 0.9742 - precision_m: 0.9808 - f1_m: 0.9775 - val_loss: 0.4662 - val_accuracy: 0.9311 - val_recall_m: 0.9274 - val_precision_m: 0.9368 - val_f1_m: 0.9320ision_m: 0 - ETA: 4s - loss: 0.0898 - accuracy: 0.9762 - recall_m: 0.9723 - precision_m: 0.9797 - f1_m: 0. - ETA: 4s - - ETA: 1s - loss: 0.0832 - accuracy: 0.97\n",
      "Epoch 80/100\n",
      "138/138 [==============================] - 12s 86ms/step - loss: 0.0948 - accuracy: 0.9681 - recall_m: 0.9640 - precision_m: 0.9746 - f1_m: 0.9692 - val_loss: 0.2923 - val_accuracy: 0.9485 - val_recall_m: 0.9458 - val_precision_m: 0.9548 - val_f1_m: 0.9502\n",
      "Epoch 81/100\n",
      "138/138 [==============================] - 12s 90ms/step - loss: 0.0504 - accuracy: 0.9825 - recall_m: 0.9812 - precision_m: 0.9831 - f1_m: 0.9821 - val_loss: 0.4007 - val_accuracy: 0.9430 - val_recall_m: 0.9430 - val_precision_m: 0.9491 - val_f1_m: 0.9460\n",
      "Epoch 82/100\n",
      "138/138 [==============================] - 12s 88ms/step - loss: 0.0825 - accuracy: 0.9775 - recall_m: 0.9748 - precision_m: 0.9806 - f1_m: 0.9776 - val_loss: 0.3811 - val_accuracy: 0.9246 - val_recall_m: 0.9210 - val_precision_m: 0.9295 - val_f1_m: 0.9251: 0.97\n",
      "Epoch 83/100\n",
      "138/138 [==============================] - 12s 86ms/step - loss: 0.0726 - accuracy: 0.9807 - recall_m: 0.9783 - precision_m: 0.9826 - f1_m: 0.9804 - val_loss: 0.3537 - val_accuracy: 0.9366 - val_recall_m: 0.9329 - val_precision_m: 0.9466 - val_f1_m: 0.9396\n",
      "Epoch 84/100\n",
      "138/138 [==============================] - 12s 89ms/step - loss: 0.0606 - accuracy: 0.9817 - recall_m: 0.9799 - precision_m: 0.9827 - f1_m: 0.9813 - val_loss: 0.2705 - val_accuracy: 0.9504 - val_recall_m: 0.9485 - val_precision_m: 0.9539 - val_f1_m: 0.9512\n",
      "Epoch 85/100\n",
      "138/138 [==============================] - 12s 88ms/step - loss: 0.0600 - accuracy: 0.9828 - recall_m: 0.9804 - precision_m: 0.9864 - f1_m: 0.9833 - val_loss: 0.4111 - val_accuracy: 0.9219 - val_recall_m: 0.9200 - val_precision_m: 0.9302 - val_f1_m: 0.9250\n",
      "Epoch 86/100\n",
      "138/138 [==============================] - 13s 93ms/step - loss: 0.0649 - accuracy: 0.9811 - recall_m: 0.9794 - precision_m: 0.9825 - f1_m: 0.9809 - val_loss: 0.4195 - val_accuracy: 0.9347 - val_recall_m: 0.9329 - val_precision_m: 0.9397 - val_f1_m: 0.9363\n",
      "Epoch 87/100\n",
      "138/138 [==============================] - 12s 89ms/step - loss: 0.0652 - accuracy: 0.9825 - recall_m: 0.9811 - precision_m: 0.9845 - f1_m: 0.9828 - val_loss: 0.4260 - val_accuracy: 0.9366 - val_recall_m: 0.9357 - val_precision_m: 0.9408 - val_f1_m: 0.9382\n",
      "Epoch 88/100\n",
      "138/138 [==============================] - 12s 88ms/step - loss: 0.0429 - accuracy: 0.9889 - recall_m: 0.9864 - precision_m: 0.9907 - f1_m: 0.9885 - val_loss: 0.3772 - val_accuracy: 0.9403 - val_recall_m: 0.9384 - val_precision_m: 0.9427 - val_f1_m: 0.9405\n",
      "Epoch 89/100\n",
      "138/138 [==============================] - 12s 88ms/step - loss: 0.0729 - accuracy: 0.9841 - recall_m: 0.9822 - precision_m: 0.9871 - f1_m: 0.9846 - val_loss: 0.3360 - val_accuracy: 0.9403 - val_recall_m: 0.9347 - val_precision_m: 0.9487 - val_f1_m: 0.9415\n",
      "Epoch 90/100\n",
      "138/138 [==============================] - 11s 82ms/step - loss: 0.0579 - accuracy: 0.9833 - recall_m: 0.9808 - precision_m: 0.9865 - f1_m: 0.9836 - val_loss: 0.3934 - val_accuracy: 0.9301 - val_recall_m: 0.9265 - val_precision_m: 0.9368 - val_f1_m: 0.9316\n",
      "Epoch 91/100\n",
      "138/138 [==============================] - 10s 76ms/step - loss: 0.0897 - accuracy: 0.9740 - recall_m: 0.9699 - precision_m: 0.9773 - f1_m: 0.9735 - val_loss: 0.4584 - val_accuracy: 0.9283 - val_recall_m: 0.9256 - val_precision_m: 0.9375 - val_f1_m: 0.9314 - recall_m: 0.9683 - precision_m: 0.9 - ETA: 2s - loss: 0.0921 - accuracy: 0.9733 - recall_m: 0.9685 -  - ETA: 1s - loss: 0.0913 - accuracy: 0.9735 - recal - ETA: 0s - loss: 0.0900 - accuracy: 0.9740 - recall_m: 0.9697 - precision_m: 0.9772 - f1\n",
      "Epoch 92/100\n",
      "138/138 [==============================] - 11s 81ms/step - loss: 0.0985 - accuracy: 0.9761 - recall_m: 0.9741 - precision_m: 0.9792 - f1_m: 0.9766 - val_loss: 0.3900 - val_accuracy: 0.9366 - val_recall_m: 0.9366 - val_precision_m: 0.9435 - val_f1_m: 0.94006 - accuracy: 0.9730 - recall_m: 0.9714 - precision_m: - ETA: 5s - l - ETA: 2s - loss: 0.1049 - accuracy: 0.9747 - recall_m: 0.972 - ETA: 1s - loss: 0.1015 - accuracy: 0.9755 - recall_m: 0.973\n",
      "Epoch 93/100\n",
      "138/138 [==============================] - 11s 77ms/step - loss: 0.0601 - accuracy: 0.9850 - recall_m: 0.9796 - precision_m: 0.9867 - f1_m: 0.9831 - val_loss: 0.4746 - val_accuracy: 0.9449 - val_recall_m: 0.9421 - val_precision_m: 0.9500 - val_f1_m: 0.9460\n",
      "Epoch 94/100\n",
      "138/138 [==============================] - 10s 76ms/step - loss: 0.0700 - accuracy: 0.9836 - recall_m: 0.9800 - precision_m: 0.9853 - f1_m: 0.9826 - val_loss: 0.4064 - val_accuracy: 0.9375 - val_recall_m: 0.9320 - val_precision_m: 0.9474 - val_f1_m: 0.9395- precision_m: 0.9878 - f1_m: 0. - ETA: 5s - loss: 0.0643 - accuracy: 0.9862 - recall_m: 0.9834 - precision_ - ETA: 5s - loss: 0.0668 - accuracy\n",
      "Epoch 95/100\n",
      "138/138 [==============================] - 11s 83ms/step - loss: 0.0510 - accuracy: 0.9873 - recall_m: 0.9848 - precision_m: 0.9889 - f1_m: 0.9868 - val_loss: 0.4693 - val_accuracy: 0.9320 - val_recall_m: 0.9292 - val_precision_m: 0.9407 - val_f1_m: 0.9348n_m: 0.9889 - f1_m: 0.98 - ETA: 0s - loss: 0.0509 - accuracy: 0.9875 - recall_m: 0.9848 - precision_\n",
      "Epoch 96/100\n",
      "138/138 [==============================] - 12s 87ms/step - loss: 0.0607 - accuracy: 0.9843 - recall_m: 0.9821 - precision_m: 0.9872 - f1_m: 0.9846 - val_loss: 0.4542 - val_accuracy: 0.9338 - val_recall_m: 0.9311 - val_precision_m: 0.9414 - val_f1_m: 0.9361\n",
      "Epoch 97/100\n",
      "138/138 [==============================] - 11s 77ms/step - loss: 0.0859 - accuracy: 0.9785 - recall_m: 0.9754 - precision_m: 0.9817 - f1_m: 0.9785 - val_loss: 0.3719 - val_accuracy: 0.9449 - val_recall_m: 0.9403 - val_precision_m: 0.9515 - val_f1_m: 0.9458accuracy: 0.9788 - recall_m: 0.9756 - precision_m: 0.981\n",
      "Epoch 98/100\n",
      "138/138 [==============================] - 11s 82ms/step - loss: 0.0945 - accuracy: 0.9807 - recall_m: 0.9762 - precision_m: 0.9843 - f1_m: 0.9802 - val_loss: 0.4032 - val_accuracy: 0.9329 - val_recall_m: 0.9265 - val_precision_m: 0.9395 - val_f1_m: 0.9328\n",
      "Epoch 99/100\n",
      "138/138 [==============================] - 11s 79ms/step - loss: 0.0776 - accuracy: 0.9793 - recall_m: 0.9755 - precision_m: 0.9818 - f1_m: 0.9786 - val_loss: 0.3008 - val_accuracy: 0.9439 - val_recall_m: 0.9393 - val_precision_m: 0.9515 - val_f1_m: 0.9453 recall_m: 0.9716  - ETA: 6s - loss: 0.0672 - accuracy: 0.9798 - recall_m: 0.9752 - precision_m: 0.9828 - f1_m:  - ETA: 5s - loss: 0.0670 - accuracy: 0.9802 - recall_m: 0.9756 - precision_m: 0.9831 - f1_m: 0. - ETA: 5s - loss: 0.0669 - accuracy: 0.9804 - rec - ETA: 4s - loss: 0.0683 - accuracy: 0.9811 - recall_m: 0.9770 - precision_m: 0.9835 -  - ETA: 3s - los - ETA: 1s - loss: 0.0761 - accuracy: 0.9795 - recall_m: 0.9\n",
      "Epoch 100/100\n",
      "138/138 [==============================] - 11s 78ms/step - loss: 0.0274 - accuracy: 0.9899 - recall_m: 0.9889 - precision_m: 0.9915 - f1_m: 0.9902 - val_loss: 0.4104 - val_accuracy: 0.9375 - val_recall_m: 0.9366 - val_precision_m: 0.9443 - val_f1_m: 0.9404l_m: 0.9\n"
     ]
    }
   ],
   "source": [
    "weights_pretrain = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch= train_generator.samples // batch_size,\n",
    "        epochs=100,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=val_generator.samples // batch_size)\n",
    "model.save_weights(f'data+.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
